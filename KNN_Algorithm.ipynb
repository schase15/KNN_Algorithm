{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Algorithm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdThzoLdr+Ap9gmW4ntx2E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schase15/KNN_Algorithm/blob/master/KNN_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6CiSLUhhlLj",
        "colab_type": "text"
      },
      "source": [
        "# Implementing K Nearest Neighbors By Hand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZyTDkUchlOo",
        "colab_type": "text"
      },
      "source": [
        "### This notebook includes the code for implementing the K Nearest Neighbors algorithm by hand\n",
        "My algorithm for K Nearest Neighbors is implemented as a Python class using only base python, numpy and scipy.\n",
        "\n",
        "I then selected a data set and compare the results of my own KNN algorithm to the results of the KNN from sklearn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grqIZnvtjyX3",
        "colab_type": "text"
      },
      "source": [
        "## Theory Behind KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jP41SdNj2F-",
        "colab_type": "text"
      },
      "source": [
        "K Nearest Neighbors is a simple machine learning model that makes predictions based off of the most similar observations in its traing data. While it can be very powerful, its predictive capability is limited to observations that are similar to what it was trained on.\n",
        "\n",
        "Unlike most other models, KNN does not 'learn' from its training dataset. Instead it holds the entire training set in memory and then compares the new observation to its stored data. KNN performs no work until a prediction is required.\n",
        "\n",
        "When a prediction is required it does exactly what it name says. The model examines the new observation and finds the most similar records (nearest neighbors) that it holds in its training set. The number of neighbors (k) the model selects from its training data is defined by the user. \n",
        "\n",
        "The prediction can be made by either returning the most common outcome (classification) or by taking the average (regression).\n",
        "\n",
        "**Some Important Notes on Using KNN**\n",
        "\n",
        "- KNN is a simple model to implement, but as a result it is limited in the types of data it can take as input. When working with KNN the phrase \"garbage in, garbage out\" is never more accurate. KNN does not handle categorical variables so everything must be pre-processed to include numerical values only. Additionally, as you will see in the next section, similar data points are found by calculating the distances between them. Those with the smallest distances are considered most similar. Intuatively, you should understand the importance of scaling your data (so that they are all being measured on the same metric.) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP8bBL25j2Iy",
        "colab_type": "text"
      },
      "source": [
        "## Titanic Dataset\n",
        "We will work with a very common and easily accessable dataset to make it easier for readers to follow along.\n",
        "\n",
        "The Titanic dataset is one of the most popular datasets for begining to learn classification models. The data is already cleaned and has a clear classification target of survived or did not survive. After only a few basic pre-processing steps, we will have a perfect dataset for our KNN model.\n",
        "\n",
        "*Download your own copy of the Titanic dataset and follow along.*  https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRn_G7faj2Nl",
        "colab_type": "text"
      },
      "source": [
        "## Algorithm Implementation\n",
        "Now that we understand the theory behind KNN, we can implement our own algorithm from scratch in three setps.\n",
        "\n",
        "Step 1. Calculate Euclidean Distance\n",
        "\n",
        "Step 2. Get Nearest Neighbors\n",
        "\n",
        "Step 3. Make Predicitons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFH3IvvGj2MM",
        "colab_type": "text"
      },
      "source": [
        "### Step 1: Calculate Euclidean Distance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9lBTiIU9ReO",
        "colab_type": "text"
      },
      "source": [
        "The formula for Euclidean Distance is:\n",
        "\n",
        "$ \\sum_{i=1}^n (x_{i}-y_{i})^2 $\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYxuyLnBw6vh",
        "colab_type": "text"
      },
      "source": [
        "The Euclidean Distance may sound complicated, and the formula may look intimitating. But the concept is very simple. The Euclidean Distance is the ordinary straight line distance between two data points. The formula can be simply derived from the Pythagorean formula: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLubqoBkw6zF",
        "colab_type": "text"
      },
      "source": [
        "Pythagorean Theorem:\n",
        "\n",
        "$c^2 = a^2 + b^2 $\n",
        "\n",
        "Where c is the Euclidean distance between datapoints a and b.\n",
        "\n",
        "For simplicity, let's first say that data point a and b are 2D.\n",
        "\n",
        "a= ($x_{1}, y_{1}$) and b= ($x_{2}, y_{2}$).\n",
        "\n",
        "So it follows that,\n",
        "\n",
        "$c^2 = (x_{1}-y_{1})^2 + (x_{2}-y_{2})^2 $\n",
        "\n",
        "$c = \\sqrt{(x_{1}-y_{1})^2 + (x_{2}-y_{2})^2} $\n",
        "\n",
        "This is the basic formula for Euclidean Distance for 2-D datapoints.\n",
        "\n",
        "However, this can be expanded to 3-D and beyond leaving us with the finalized formula of Euclidean Distance we saw above.\n",
        "\n",
        "$c = \\sqrt{(x_{1}-y_{1})^2 + (x_{2}-y_{2})^2 + (x_{3}-y_{3})^2 + ... + (x_{n}-y_{n})^2} $\n",
        "\n",
        "More succintly written as,\n",
        "\n",
        "$ \\sum_{i=1}^n (x_{i}-y_{i})^2 $\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le3fSJIiEXLC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mRkmjdBEXOI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC3OurimEXIc",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKZc5AmShl5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRtDeSs8hlx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbazOqDlmDxe",
        "colab_type": "text"
      },
      "source": [
        "### Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAoUTbNhmIhv",
        "colab_type": "text"
      },
      "source": [
        "*Jason Brownlee, 'Develop k-Nearest Neighbors in Python From Scratch', Machine Learning Mastery. https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/*"
      ]
    }
  ]
}